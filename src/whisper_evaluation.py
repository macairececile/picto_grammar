"""
Script to read the predictions from whisper, evaluate, and save the evaluation in a .csv file.

Example of use: python create_train_dev_test --datafile 'corpus.csv' --whisper '/whisper_large/' --save 'whisper_eval/'
"""

import pandas as pd
import evaluate
import csv
from argparse import ArgumentParser, RawTextHelpFormatter

wer_metric = evaluate.load("wer")
cer_metric = evaluate.load("cer")

punctuations = '!?\":,/.;()[]'
punc_table = str.maketrans({key: None for key in punctuations})


def read_tsv(csv_file):
    """
        Read csv file in a dataframe

        Arguments
        ---------
        csv_file: str

        Returns
        -------
        A dataframe with the data.
    """
    return pd.read_csv(csv_file, sep='\t')


def process_whisper_output(text):
    """
        Process the prediction from whisper model

        Arguments
        ---------
        text: str

        Returns
        -------
        The processed text.
    """
    t = text.replace('\n', '')
    a = t.translate(punc_table)
    b = a.replace('-', ' ')
    return ''.join(b.lower().strip())


def get_data_from_whisper(directory):
    """
        Read the data generated by whisper.

        Arguments
        ---------
        directory: str

        Returns
        -------
        The clip names and the predictions of the whisper model
    """
    clips, preds = [], []
    with open(directory + "out.txt", 'r') as f:
        csv_reader = csv.reader(f, delimiter='\t')
        for row in csv_reader:
            clips.append(row[0])
            preds.append(process_whisper_output(row[1]))
    return clips, preds


def merge_data_from_csv_whisper(clips, preds, dataframe):
    """
        Merge the data from csv and preds of whisper.

        Arguments
        ---------
        clips: clip names
        preds: predictions of the model
        dataframe: dataframe

        Returns
        -------
        A list with all information from whisper.
    """
    data_whisper = []
    for i, row in dataframe.iterrows():
        identifier = clips.index(row["clips"])
        d = (row["clips"], row["text"], preds[identifier], row["corpus_name"])
        data_whisper.append(d)
    return data_whisper


def compute_wer_all(predictions, references):
    """
        Compute the WER and CER from the whisper predictions.

        Arguments
        ---------
        predictions: list
        references: list
    """
    wer_score = wer_metric.compute(predictions=predictions, references=references)
    cer_score = cer_metric.compute(predictions=predictions, references=references)
    print("WER: ", wer_score)
    print("CER: ", cer_score)


def evaluate(data_whisper):
    """
        Compute the WER and CER per sentence, and then for the entire corpus.

        Arguments
        ---------
        data_whisper: list

        Returns
        -------
        Two lists, with the WER scores and with the CER scores.
    """
    wers, cers = [], []
    for d in data_whisper:
        if d[1] != '' and d[2] != '':
            wers.append(wer_metric.compute(predictions=[d[2]], references=[d[1]]))
            cers.append(cer_metric.compute(predictions=[d[2]], references=[d[1]]))
        else:
            wers.append(100.0)
            cers.append(100.0)
    compute_wer_all(predictions=[d[2] for d in data_whisper], references=[d[1] for d in data_whisper])
    return wers, cers


def evaluate_per_corpus_name(data_whisper):
    """
        Compute the WER and CER per corpus name.

        Arguments
        ---------
        data_whisper: list
    """
    corpus_names = list(set([d[3] for d in data_whisper]))
    for n in corpus_names:
        corpus_data = list(filter(lambda x: x[3] == n, data_whisper))
        print("---------------\nWER & CER on subcorpus : " + n)
        compute_wer_all(predictions=[d[2] for d in corpus_data], references=[d[1] for d in corpus_data])


def save_whisper_evaluation(save_path, data_whisper, wers, cers):
    """
        Save the evaluation data in a csv file.

        Arguments
        ---------
        save_path: str
        data_whisper: list
        wers: list
        cers: list
    """
    df = pd.DataFrame.from_dict(
        {'clips': [d[0] for d in data_whisper], 'text': [d[1] for d in data_whisper],
         'hyp': [d[2] for d in data_whisper], 'wer': wers, 'cer': cers, 'corpus_name': [d[3] for d in data_whisper]})
    csv_file = 'whisper_results.csv'
    df.to_csv(save_path + csv_file, index=False, header=True, sep='\t')


def main(args):
    """
        Pipeline to evaluate the predictions from whisper and save the results in a dataframe.
    """
    data = read_tsv(args.datafile)
    clips, preds = get_data_from_whisper(args.whisper)
    data_whisper = merge_data_from_csv_whisper(clips, preds, data)
    wers, cers = evaluate(data_whisper)
    evaluate_per_corpus_name(data_whisper)
    save_whisper_evaluation(args.save, data_whisper, wers, cers)


# parser = ArgumentParser(description="Evaluate the preds from whisper.",
#                         formatter_class=RawTextHelpFormatter)
# parser.add_argument('--datafile', type=str, required=True,
#                     help="")
# parser.add_argument('--whisper', type=str, required=True,
#                     help="")
# parser.add_argument('--save', type=str, required=True,
#                     help="")
# parser.set_defaults(func=main)
# args = parser.parse_args()
# args.func(args)
